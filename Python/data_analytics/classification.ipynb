{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 모델\n",
    "# 로지스틱 -> 데이터가 선형 관계를 가질 때\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# 릿지 -> L2, 데이터의 차원이 많고 다중공선성이 존재할 때\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=1.0)\n",
    "# 라쏘 -> L1, 불필요한 특성 자동 제거\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=0.1)\n",
    "# 엘라스틱넷 -> LogisticRegression + Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# 비선형 모델\n",
    "# 랜덤포레스트 -> 여러 개의 결정 트리를 조합, 이상치에 강함\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimator=100, random_state=42)\n",
    "# 그래디언트 부스팅 -> 데이터가 복잡하고 비선형적.\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "# SVM -> 비선형 분류 모델\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', C=1.0)\n",
    "\n",
    "# 대용량 데이터에서 강력한 성능을 보이는 모델\n",
    "# xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBRegressor(n_estimators= 100, learning_rate=0.1)\n",
    "# lightgbm -> \n",
    "from lightgbm import LGBMRegressor\n",
    "model = LGBMRegressor(n_estimators=100, learning_rate=0.1)\n",
    "# catboost -> 범주형 변수 처리에 강함\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostRegressor(n_estimators=100, learning_rate=0.1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러 모델을 사용\n",
    "- 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "\n",
    "# 모델 학습에 필요없는 특정 변수 제거하기\n",
    "df_processing = df.drop('name', axis=1,inplace=False)\n",
    "\n",
    "# 데이터 전처리\n",
    "# 정규화 MinMax\n",
    "df_norm = preprocessing.minmax_scale(df_processing)\n",
    "df_processed = pd.DataFrame(df_norm)\n",
    "df_processed.columns = df_processing.columns\n",
    "\n",
    "# 종속변수와 독립변수 분리\n",
    "feature_columns = df_processed.columns.difference([\"stat\"]) # 종속 변수\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['status'].astype('category')\n",
    "\n",
    "# 테스트와 트레인셋 분리\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 테스트할 모델 리스트\n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"Random Forest\" : RandomForestClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\" : GradientBoostingClassifier(n_estimators=100),\n",
    "    \"Support Vector Machine\" : SVC(kernel='rbf'),\n",
    "    \"XGBoost\" : XGBClassifier(n_estimators=100, user_label_encoder=False,eval_metric='logloss' ,learning_rate=0.1)\n",
    "    \n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임\n",
    "result = []\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "for name, model in models.items() :\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y)\n",
    "    result.append({'Model':name, 'Accuracy':acc})\n",
    "\n",
    "# 결과 출력\n",
    "df_result = pd.DataFrame(result).sort_values(by='Accuracy', acending=False)\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "\n",
    "# 모델 학습에 필요없는 특정 변수 제거하기\n",
    "df_processing = df.drop('name', axis=1,inplace=False)\n",
    "\n",
    "# 결측치\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)  # 나이 결측치 → 중앙값으로 대체\n",
    "df['Income'].fillna(df['Income'].mean(), inplace=True)  # 소득 결측치 → 평균값으로 대체\n",
    "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)  # 성별 결측치 → 최빈값으로 대체\n",
    "\n",
    "# IQR 계산\n",
    "Q1 = df['Age'].quantile(0.25)\n",
    "Q3 = df['Age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 이상치 기준 설정\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# 이상치 필터링\n",
    "df_no_outliers = df[(df['Age'] >= lower_bound) & (df['Age'] <= upper_bound)]\n",
    "print(df_no_outliers)\n",
    "\n",
    "# 'sex' 변수를 원-핫 인코딩 적용\n",
    "df_processing = pd.get_dummies(df_processing, columns=['sex'], drop_first=True)  # drop_first=True로 다중공선성 방지\n",
    "\n",
    "# 데이터 전처리\n",
    "# 정규화 MinMax\n",
    "df_norm = preprocessing.minmax_scale(df_processing)\n",
    "df_processed = pd.DataFrame(df_norm)\n",
    "df_processed.columns = df_processing.columns\n",
    "\n",
    "# 종속변수와 독립변수 분리\n",
    "feature_columns = df_processed.columns.difference([\"stat\"]) # 종속 변수\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['status'].astype('category')\n",
    "\n",
    "# 테스트와 트레인셋 분리\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 테스트할 모델 리스트\n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"Random Forest\" : RandomForestClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\" : GradientBoostingClassifier(n_estimators=100),\n",
    "    \"Support Vector Machine\" : SVC(kernel='rbf'),\n",
    "    \"XGBoost\" : XGBClassifier(n_estimators=100, user_label_encoder=False,eval_metric='logloss' ,learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임\n",
    "result = []\n",
    "model_predictions = {}\n",
    "# 모델 학습 및 평가\n",
    "for name, model in models.items() :\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y)\n",
    "    result.append({'Model':name, 'Accuracy':acc})\n",
    "\n",
    "    model_predictions[name] = pred_y\n",
    "\n",
    "# 결과 출력\n",
    "df_result = pd.DataFrame(result).sort_values(by='Accuracy', ascending=False)\n",
    "print(df_result)\n",
    "best_model = df_result.iloc[0]['Model']\n",
    "print(best_model)\n",
    "pd.DataFrame(model_predictions[best_model]).to_csv('result.csv', index=False, encoding='utf-8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀 문제\n",
    "- 모델 이름 변경\n",
    "- 평가지표 변경 -> mean_squared_error(), mean_absolute_error(), r2_score()\n",
    "- 종속변수 타입 -> 'float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 📌 1. 데이터 불러오기\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "\n",
    "# 📌 2. 필요없는 컬럼 제거\n",
    "df_processing = df.drop(columns=['name'])\n",
    "\n",
    "# 📌 3. 'sex' 변수가 있다면 원-핫 인코딩 적용\n",
    "if 'sex' in df_processing.columns:\n",
    "    df_processing = pd.get_dummies(df_processing, columns=['sex'], drop_first=True)\n",
    "\n",
    "# 📌 4. 데이터 정규화 (MinMax 정규화)\n",
    "df_norm = preprocessing.minmax_scale(df_processing)\n",
    "df_processed = pd.DataFrame(df_norm, columns=df_processing.columns)\n",
    "\n",
    "# 📌 5. 종속변수와 독립변수 분리 (회귀 문제이므로 `y`를 float으로 변환)\n",
    "X = df_processed.drop(columns=[\"status\"])  # 독립 변수\n",
    "y = df_processed[\"status\"].astype(\"float\")  # 회귀 문제에서는 숫자형으로 유지\n",
    "\n",
    "# 📌 6. 학습/테스트 데이터 분리\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 📌 7. 회귀 모델 리스트\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# 📌 8. 결과를 저장할 데이터프레임\n",
    "results = []\n",
    "model_predictions = {}\n",
    "\n",
    "# 📌 9. 모델 학습 및 평가\n",
    "for name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "\n",
    "    mse = mean_squared_error(test_y, pred_y)  # 평균제곱오차 (MSE)\n",
    "    mae = mean_absolute_error(test_y, pred_y)  # 평균절대오차 (MAE)\n",
    "    r2 = r2_score(test_y, pred_y)  # 결정계수 (R²)\n",
    "\n",
    "    results.append({'Model': name, 'MSE': mse, 'MAE': mae, 'R2 Score': r2})\n",
    "    model_predictions[name] = pred_y\n",
    "\n",
    "# 📌 10. 결과 정렬 후 가장 좋은 모델 선택 (R2 Score 기준)\n",
    "df_result = pd.DataFrame(results).sort_values(by='R2 Score', ascending=False)\n",
    "print(df_result)\n",
    "\n",
    "best_model = df_result.iloc[0]['Model']\n",
    "print(f\"🏆 가장 높은 성능을 보인 모델: {best_model}\")\n",
    "\n",
    "# 📌 11. 원본 df에 최적 모델의 예측값 추가\n",
    "df.loc[test_x.index, f\"Prediction_{best_model}\"] = model_predictions[best_model]\n",
    "\n",
    "# 📌 12. 최적 모델 저장\n",
    "joblib.dump(models[best_model], \"best_regression_model.pkl\")\n",
    "print(f\"✅ 최적 회귀 모델 ({best_model})이 'best_regression_model.pkl'로 저장되었습니다!\")\n",
    "\n",
    "# 📌 13. 결과 CSV 저장\n",
    "df.to_csv('regression_result.csv', index=False, encoding='utf-8')\n",
    "print(\"✅ 예측 결과가 'regression_result.csv' 파일로 저장되었습니다!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
