{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ í˜• ëª¨ë¸\n",
    "# ë¡œì§€ìŠ¤í‹± -> ë°ì´í„°ê°€ ì„ í˜• ê´€ê³„ë¥¼ ê°€ì§ˆ ë•Œ\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# ë¦¿ì§€ -> L2, ë°ì´í„°ì˜ ì°¨ì›ì´ ë§ê³  ë‹¤ì¤‘ê³µì„ ì„±ì´ ì¡´ì¬í•  ë•Œ\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=1.0)\n",
    "# ë¼ì˜ -> L1, ë¶ˆí•„ìš”í•œ íŠ¹ì„± ìë™ ì œê±°\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=0.1)\n",
    "# ì—˜ë¼ìŠ¤í‹±ë„· -> LogisticRegression + Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# ë¹„ì„ í˜• ëª¨ë¸\n",
    "# ëœë¤í¬ë ˆìŠ¤íŠ¸ -> ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ ì¡°í•©, ì´ìƒì¹˜ì— ê°•í•¨\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimator=100, random_state=42)\n",
    "# ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… -> ë°ì´í„°ê°€ ë³µì¡í•˜ê³  ë¹„ì„ í˜•ì .\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "# SVM -> ë¹„ì„ í˜• ë¶„ë¥˜ ëª¨ë¸\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', C=1.0)\n",
    "\n",
    "# ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸\n",
    "# xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBRegressor(n_estimators= 100, learning_rate=0.1)\n",
    "# lightgbm -> \n",
    "from lightgbm import LGBMRegressor\n",
    "model = LGBMRegressor(n_estimators=100, learning_rate=0.1)\n",
    "# catboost -> ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ì— ê°•í•¨\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostRegressor(n_estimators=100, learning_rate=0.1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì—¬ëŸ¬ ëª¨ë¸ì„ ì‚¬ìš©\n",
    "- ë¶„ë¥˜ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµì— í•„ìš”ì—†ëŠ” íŠ¹ì • ë³€ìˆ˜ ì œê±°í•˜ê¸°\n",
    "df_processing = df.drop('name', axis=1,inplace=False)\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# ì •ê·œí™” MinMax\n",
    "df_norm = preprocessing.minmax_scale(df_processing)\n",
    "df_processed = pd.DataFrame(df_norm)\n",
    "df_processed.columns = df_processing.columns\n",
    "\n",
    "# ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬\n",
    "feature_columns = df_processed.columns.difference([\"stat\"]) # ì¢…ì† ë³€ìˆ˜\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['status'].astype('category')\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ì™€ íŠ¸ë ˆì¸ì…‹ ë¶„ë¦¬\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"Random Forest\" : RandomForestClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\" : GradientBoostingClassifier(n_estimators=100),\n",
    "    \"Support Vector Machine\" : SVC(kernel='rbf'),\n",
    "    \"XGBoost\" : XGBClassifier(n_estimators=100, user_label_encoder=False,eval_metric='logloss' ,learning_rate=0.1)\n",
    "    \n",
    "}\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„\n",
    "result = []\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "for name, model in models.items() :\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y)\n",
    "    result.append({'Model':name, 'Accuracy':acc})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "df_result = pd.DataFrame(result).sort_values(by='Accuracy', acending=False)\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµì— í•„ìš”ì—†ëŠ” íŠ¹ì • ë³€ìˆ˜ ì œê±°í•˜ê¸°\n",
    "df_processing = df.drop('name', axis=1,inplace=False)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)  # ë‚˜ì´ ê²°ì¸¡ì¹˜ â†’ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "df['Income'].fillna(df['Income'].mean(), inplace=True)  # ì†Œë“ ê²°ì¸¡ì¹˜ â†’ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)  # ì„±ë³„ ê²°ì¸¡ì¹˜ â†’ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "\n",
    "# IQR ê³„ì‚°\n",
    "Q1 = df['Age'].quantile(0.25)\n",
    "Q3 = df['Age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# ì´ìƒì¹˜ ê¸°ì¤€ ì„¤ì •\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# ì´ìƒì¹˜ í•„í„°ë§\n",
    "df_no_outliers = df[(df['Age'] >= lower_bound) & (df['Age'] <= upper_bound)]\n",
    "print(df_no_outliers)\n",
    "\n",
    "# 'sex' ë³€ìˆ˜ë¥¼ ì›-í•« ì¸ì½”ë”© ì ìš©\n",
    "df_processing = pd.get_dummies(df_processing, columns=['sex'], drop_first=True)  # drop_first=Trueë¡œ ë‹¤ì¤‘ê³µì„ ì„± ë°©ì§€\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# ì •ê·œí™” MinMax\n",
    "df_norm = preprocessing.minmax_scale(df_processing)\n",
    "df_processed = pd.DataFrame(df_norm)\n",
    "df_processed.columns = df_processing.columns\n",
    "\n",
    "# ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬\n",
    "feature_columns = df_processed.columns.difference([\"stat\"]) # ì¢…ì† ë³€ìˆ˜\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['status'].astype('category')\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ì™€ íŠ¸ë ˆì¸ì…‹ ë¶„ë¦¬\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"Random Forest\" : RandomForestClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\" : GradientBoostingClassifier(n_estimators=100),\n",
    "    \"Support Vector Machine\" : SVC(kernel='rbf'),\n",
    "    \"XGBoost\" : XGBClassifier(n_estimators=100, user_label_encoder=False,eval_metric='logloss' ,learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„\n",
    "result = []\n",
    "model_predictions = {}\n",
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "for name, model in models.items() :\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y)\n",
    "    result.append({'Model':name, 'Accuracy':acc})\n",
    "\n",
    "    model_predictions[name] = pred_y\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "df_result = pd.DataFrame(result).sort_values(by='Accuracy', ascending=False)\n",
    "print(df_result)\n",
    "best_model = df_result.iloc[0]['Model']\n",
    "print(best_model)\n",
    "pd.DataFrame(model_predictions[best_model]).to_csv('result.csv', index=False, encoding='utf-8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# íšŒê·€ ë¬¸ì œ\n",
    "- ëª¨ë¸ ì´ë¦„ ë³€ê²½\n",
    "- í‰ê°€ì§€í‘œ ë³€ê²½ -> mean_squared_error(), mean_absolute_error(), r2_score()\n",
    "- ì¢…ì†ë³€ìˆ˜ íƒ€ì… -> 'float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ğŸ“Œ 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/Parkinsons.csv')\n",
    "\n",
    "# ğŸ“Œ 2. í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì œê±°\n",
    "df_processing = df.drop(columns=['name'])\n",
    "\n",
    "# ğŸ“Œ 3. 'sex' ë³€ìˆ˜ê°€ ìˆë‹¤ë©´ ì›-í•« ì¸ì½”ë”© ì ìš©\n",
    "if 'sex' in df_processing.columns:\n",
    "    df_processing = pd.get_dummies(df_processing, columns=['sex'], drop_first=True)\n",
    "\n",
    "# ğŸ“Œ 4. ë°ì´í„° ì •ê·œí™” (MinMax ì •ê·œí™”)\n",
    "df_norm = preprocessing.minmax_scale(df_processing)\n",
    "df_processed = pd.DataFrame(df_norm, columns=df_processing.columns)\n",
    "\n",
    "# ğŸ“Œ 5. ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬ (íšŒê·€ ë¬¸ì œì´ë¯€ë¡œ `y`ë¥¼ floatìœ¼ë¡œ ë³€í™˜)\n",
    "X = df_processed.drop(columns=[\"status\"])  # ë…ë¦½ ë³€ìˆ˜\n",
    "y = df_processed[\"status\"].astype(\"float\")  # íšŒê·€ ë¬¸ì œì—ì„œëŠ” ìˆ«ìí˜•ìœ¼ë¡œ ìœ ì§€\n",
    "\n",
    "# ğŸ“Œ 6. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ğŸ“Œ 7. íšŒê·€ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# ğŸ“Œ 8. ê²°ê³¼ë¥¼ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„\n",
    "results = []\n",
    "model_predictions = {}\n",
    "\n",
    "# ğŸ“Œ 9. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "for name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "\n",
    "    mse = mean_squared_error(test_y, pred_y)  # í‰ê· ì œê³±ì˜¤ì°¨ (MSE)\n",
    "    mae = mean_absolute_error(test_y, pred_y)  # í‰ê· ì ˆëŒ€ì˜¤ì°¨ (MAE)\n",
    "    r2 = r2_score(test_y, pred_y)  # ê²°ì •ê³„ìˆ˜ (RÂ²)\n",
    "\n",
    "    results.append({'Model': name, 'MSE': mse, 'MAE': mae, 'R2 Score': r2})\n",
    "    model_predictions[name] = pred_y\n",
    "\n",
    "# ğŸ“Œ 10. ê²°ê³¼ ì •ë ¬ í›„ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì„ íƒ (R2 Score ê¸°ì¤€)\n",
    "df_result = pd.DataFrame(results).sort_values(by='R2 Score', ascending=False)\n",
    "print(df_result)\n",
    "\n",
    "best_model = df_result.iloc[0]['Model']\n",
    "print(f\"ğŸ† ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì¸ ëª¨ë¸: {best_model}\")\n",
    "\n",
    "# ğŸ“Œ 11. ì›ë³¸ dfì— ìµœì  ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ì¶”ê°€\n",
    "df.loc[test_x.index, f\"Prediction_{best_model}\"] = model_predictions[best_model]\n",
    "\n",
    "# ğŸ“Œ 12. ìµœì  ëª¨ë¸ ì €ì¥\n",
    "joblib.dump(models[best_model], \"best_regression_model.pkl\")\n",
    "print(f\"âœ… ìµœì  íšŒê·€ ëª¨ë¸ ({best_model})ì´ 'best_regression_model.pkl'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ğŸ“Œ 13. ê²°ê³¼ CSV ì €ì¥\n",
    "df.to_csv('regression_result.csv', index=False, encoding='utf-8')\n",
    "print(\"âœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ 'regression_result.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
