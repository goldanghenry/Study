{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 라이브러리 설치 및 환경 설정\n",
    "- 예시코드 : https://puleugo.tistory.com/10\n",
    "- MediaPipe Studio : https://mediapipe-studio.webapps.google.com/home\n",
    "- Python setup : https://developers.google.com/mediapipe/solutions/setup_python\n",
    "- Python code : https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/python\n",
    "- Documention : https://developers.google.com/mediapipe\n",
    "- land mark & Gesture classification bundle : https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer#gesture_classification_model_bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip install --upgrade pip\n",
    "!pip install opencv-python\n",
    "!pip install mediapipe\n",
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protobuf 설치\n",
    "# upgrade\n",
    "!pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치 경로 확인 -> site-packages/google/protobuf/internal \n",
    "# 안에 있는 builder.py를 찾아서 바탕화면에 copy\n",
    "!pip show protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install protobuf==3.19.4 로 버전을 낮춘다\n",
    "# builder.py를 다시 pip show protobuf로 경로를 찾아서\n",
    "# site-packages/google/protobuf/internal에 넣어준다.\n",
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 카메라로부터 영상 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14768\\973763387.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"VideoFrame\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while cv2.waitKey(33) < 0:\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 손가락 랜드마크 감지\n",
    "- 랜드마크 좌표 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"카메라를 찾을 수 없습니다.\")\n",
    "      continue\n",
    "\n",
    "    # 이미지 좌우로 뒤집기\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "        \n",
    "        # 각 랜드마크의 좌표를 표시합니다.\n",
    "        image_height, image_width, _ = image.shape\n",
    "        for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "            x = int(landmark.x * image_width)\n",
    "            y = int(landmark.y * image_height)\n",
    "            cv2.putText(image, f'LM{idx} ({x}, {y})', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 제스처 감지\n",
    "이 코드에서는 손의 검지만을 사용하여 커서 모드를 제어합니다. 검지의 두 번째 관절 (PIP)과 세 번째 관절 (DIP) 그리고 손목과의 상대적 위치를 비교하여 검지를 펼치고 있는지 여부를 확인합니다. 검지를 펼친 경우 \"커서 모드입니다\"가 화면 왼쪽 위에 표시됩니다. 검지를 접으면 커서 모드가 해제됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 커서 모드 진입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  \n",
    "  cursor_mode = False  # 초기에는 커서 모드가 아님을 나타냅니다.\n",
    "\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"카메라를 찾을 수 없습니다.\")\n",
    "      continue\n",
    "\n",
    "    # 이미지 좌우로 뒤집기\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "        \n",
    "        # 검지와 중지 손가락 끝점 좌표를 가져옵니다.\n",
    "        index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "        \n",
    "        # 검지 손가락을 펼치고 나머지 손가락은 접었는지 확인합니다.\n",
    "        if index_finger_tip.y < middle_finger_tip.y:\n",
    "          cursor_mode = True  # 커서 모드로 전환합니다.\n",
    "          cv2.putText(image, \"cursor_mode\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "          cursor_mode = False  # 커서 모드가 아님을 나타냅니다.\n",
    "\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    # esc 키로 종료\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 커서모드 + 검지 트래킹 + 커서모드 종료 모션 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  \n",
    "  cursor_mode = False  # 초기에는 커서 모드가 아님을 나타냅니다.\n",
    "\n",
    "  cursor_position = None  # 커서 위치 초기화\n",
    "\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"카메라를 찾을 수 없습니다.\")\n",
    "      continue\n",
    "\n",
    "    # 이미지 좌우로 뒤집기\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "        \n",
    "        # 검지와 중지 손가락 끝점 좌표를 가져옵니다.\n",
    "        index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "        \n",
    "        # 검지 손가락을 펼치고 나머지 손가락은 접었는지 확인합니다.\n",
    "        if index_finger_tip.y < middle_finger_tip.y:\n",
    "          cursor_mode = True  # 커서 모드로 전환합니다.\n",
    "          cursor_position = (int(index_finger_tip.x * image.shape[1]), int(index_finger_tip.y * image.shape[0]))\n",
    "          cv2.putText(image, \"Cursor Mode\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "          cv2.circle(image, cursor_position, 10, (0, 0, 255), -1)  # 커서 위치에 원 그리기\n",
    "\n",
    "          # 화살표 그리기\n",
    "          cv2.arrowedLine(image, cursor_position, (cursor_position[0] + 50, cursor_position[1]), (255, 0, 0), 2)\n",
    "          cv2.arrowedLine(image, cursor_position, (cursor_position[0], cursor_position[1] + 50), (0, 255, 0), 2)\n",
    "          \n",
    "        else:\n",
    "          cursor_mode = False  # 커서 모드가 아님을 나타냅니다.\n",
    "          cursor_position = None  # 커서 위치 초기화\n",
    "\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    # esc 키로 종료\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 윈도우 커서 제어\n",
    "OpenCV와 Mediapipe를 사용하여 손을 감지하고, 감지된 손의 위치를 기반으로 마우스 커서를 조작할 수 있습니다.\n",
    "\n",
    "아래는 이를 구현하는 간단한 예제 코드입니다. 이 예제에서는 손의 중심을 사용하여 마우스 커서를 제어합니다\n",
    "\n",
    "- pyautogui doc : https://wikidocs.net/85581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "\n",
    "# Mediapipe 라이브러리를 사용하기 위해 모듈을 import 합니다.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 웹캠에서 영상을 받아오기 위해 VideoCapture 객체를 생성합니다.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Hands 모델을 사용하여 손을 추적합니다.\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # 웹캠으로부터 현재 프레임을 읽어옵니다.\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라를 찾을 수 없습니다.\")\n",
    "            break\n",
    "\n",
    "        # 이미지를 좌우로 뒤집습니다.\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Mediapipe 라이브러리에서 사용하는 RGB 형식으로 이미지를 변환합니다.\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Hands 모델을 사용하여 손을 감지합니다.\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # 손 중심의 x, y 좌표를 계산합니다.\n",
    "                cx, cy = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * image.shape[1]), int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * image.shape[0])\n",
    "\n",
    "                # 마우스 커서를 손 중심으로 이동시킵니다.\n",
    "                pyautogui.moveTo(cx, cy)\n",
    "\n",
    "                # 손을 화면에 그립니다.\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # 화면에 영상을 출력합니다.\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        # 'esc' 키를 누르면 루프를 종료합니다.\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "# 웹캠 리소스를 해제하고 모든 창을 닫습니다.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "커서 모드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 커서의 이동은 검지를 폈을때만 가능하도록, 이때는 클릭되면 안됨\n",
    "2. 검지와 중지를 펼쳐서 붙이면 클릭\n",
    "3. 손가락을 모두 펼치면 더블클릭\n",
    "4. 검지와 엄지를 붙이는 모양으로 화면 확대\n",
    "5. 검지와 엄지를 펼치면 화면 축소\n",
    "6. 주먹을 쥐면 커서모드를 종료시켜줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    cursor_mode = False\n",
    "    clicking = False\n",
    "    double_click = False\n",
    "    zoom_in = False\n",
    "    zoom_out = False\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라를 찾을 수 없습니다.\")\n",
    "            break\n",
    "\n",
    "        image = cv2.flip(image, 1)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "                ring_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "                pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "                index_finger_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "                thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP]\n",
    "\n",
    "                if all(finger.y > thumb_mcp.y for finger in [middle_finger_tip, ring_finger_tip, pinky_tip]):\n",
    "                    cursor_mode = True\n",
    "                    cursor_position = (int(index_finger_tip.x * image.shape[1]), int(index_finger_tip.y * image.shape[0]))\n",
    "                    pyautogui.moveTo(cursor_position[0], cursor_position[1], duration=0.1)\n",
    "                else:\n",
    "                    cursor_mode = False\n",
    "\n",
    "                if all(finger.x < index_finger_tip.x for finger in [middle_finger_tip, index_finger_tip]):\n",
    "                    clicking = True\n",
    "                else:\n",
    "                    clicking = False\n",
    "\n",
    "                if all(finger.x < thumb_mcp.x for finger in [index_finger_tip, middle_finger_tip, thumb_tip]):\n",
    "                    double_click = True\n",
    "                else:\n",
    "                    double_click = False\n",
    "\n",
    "                if np.linalg.norm(np.array([index_finger_tip.x, index_finger_tip.y]) - np.array([thumb_tip.x, thumb_tip.y])) < 0.03:\n",
    "                    zoom_in = True\n",
    "                else:\n",
    "                    zoom_in = False\n",
    "\n",
    "                if np.linalg.norm(np.array([index_finger_tip.x, index_finger_tip.y]) - np.array([thumb_tip.x, thumb_tip.y])) > 0.1:\n",
    "                    zoom_out = True\n",
    "                else:\n",
    "                    zoom_out = False\n",
    "\n",
    "                if all(finger.x > index_finger_tip.x for finger in [middle_finger_tip, index_finger_tip]):\n",
    "                    cursor_mode = False\n",
    "                    clicking = False\n",
    "                    double_click = False\n",
    "                    zoom_in = False\n",
    "                    zoom_out = False\n",
    "\n",
    "                if cursor_mode:\n",
    "                    cv2.circle(image, cursor_position, 10, (0, 0, 255), -1)\n",
    "                    cv2.putText(image, \"Cursor Mode\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                    if cursor_position is not None:\n",
    "                        arrow_end_x = int(cursor_position[0] + 50)\n",
    "                        arrow_end_y = int(cursor_position[1] + 50)\n",
    "                        cv2.arrowedLine(image, cursor_position, (arrow_end_x, cursor_position[1]), (255, 0, 0), 2)\n",
    "                        cv2.arrowedLine(image, cursor_position, (cursor_position[0], arrow_end_y), (0, 255, 0), 2)\n",
    "\n",
    "                if clicking:\n",
    "                    pyautogui.click()\n",
    "\n",
    "                if double_click:\n",
    "                    pyautogui.doubleClick()\n",
    "\n",
    "                if zoom_in:\n",
    "                    pyautogui.scroll(1)\n",
    "\n",
    "                if zoom_out:\n",
    "                    pyautogui.scroll(-1)\n",
    "\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
